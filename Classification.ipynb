{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e461764f-bbe8-418a-9ff4-f8f338f372e5",
   "metadata": {},
   "source": [
    "# Classification Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27d344f-8b13-466f-a784-953224f0f938",
   "metadata": {},
   "source": [
    "## 1 Imports and Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b97d4e5-0e22-4fad-adb5-d39148998eab",
   "metadata": {},
   "source": [
    "### 1.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "534b1400-5686-4c46-ae73-6d149f0408c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import allel\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ad93f-9bc7-4811-85a9-1add9be16f35",
   "metadata": {},
   "source": [
    "### 1.2 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb3590f-1a8e-46ee-9e60-4364682f2bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['syn2',\n",
       " 'syn1.zip',\n",
       " 'real2_part2',\n",
       " 'syn5',\n",
       " 'syn1',\n",
       " 'real2_part1',\n",
       " 'Notebook_1.ipynb',\n",
       " 'test',\n",
       " 'real1.zip',\n",
       " 'real2_part2.zip',\n",
       " 'real2_part1.zip',\n",
       " 'syn4',\n",
       " 'test.zip',\n",
       " 'syn3',\n",
       " 'real1',\n",
       " '.ipynb_checkpoints',\n",
       " 'syn4.zip',\n",
       " 'syn3.zip',\n",
       " 'syn2.zip',\n",
       " 'Classification.ipynb',\n",
       " 'syn5.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME = \"cs4220/ass1\"\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8aff2689-fd44-4e86-b952-dd54d4df9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['real1', 'syn1', 'syn2', 'syn3', 'syn4', 'syn5']\n",
    "methods = ['freebayes', 'mutect2', 'varscan', 'vardict']\n",
    "dfs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8939723d-4635-47f2-af1a-a97169009187",
   "metadata": {},
   "source": [
    "## 2. Get data from files\n",
    "\n",
    "Skip 2.1 and 2.2 if you already have the pickle file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c9f95-7d15-43cd-a6a6-bb5619417ba2",
   "metadata": {},
   "source": [
    "### 2.1 Load data to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d2009e1-2c48-4897-9e47-f9a3c5ce4a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read freebayes from real1\n",
      "Read mutect2 from real1\n",
      "Read varscan from real1\n",
      "Read vardict from real1\n",
      "Read freebayes from syn1\n",
      "Read mutect2 from syn1\n",
      "Read varscan from syn1\n",
      "Read vardict from syn1\n",
      "Read freebayes from syn2\n",
      "Read mutect2 from syn2\n",
      "Read varscan from syn2\n",
      "Read vardict from syn2\n",
      "Read freebayes from syn3\n",
      "Read mutect2 from syn3\n",
      "Read varscan from syn3\n",
      "Read vardict from syn3\n",
      "Read freebayes from syn4\n",
      "Read mutect2 from syn4\n",
      "Read varscan from syn4\n",
      "Read vardict from syn4\n",
      "Read freebayes from syn5\n",
      "Read mutect2 from syn5\n",
      "Read varscan from syn5\n",
      "Read vardict from syn5\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    temp_dfs = {}\n",
    "    for method in methods:\n",
    "        temp_df = allel.vcf_to_dataframe(dataset+'/'+dataset+'-'+method+'.vcf.gz')\n",
    "        temp_dfs[method] = temp_df\n",
    "        print(f'Read {method} from {dataset}')\n",
    "    merged = temp_dfs['freebayes'][['CHROM', 'POS', 'FILTER_PASS']].merge(temp_dfs['mutect2'][['CHROM', 'POS', 'FILTER_PASS']], \n",
    "                                                   how='outer', on=['CHROM', 'POS'], \n",
    "                                                   suffixes=['_freebayes', '_mutect2']).merge(temp_dfs['vardict'][['CHROM', 'POS', 'FILTER_PASS']], \n",
    "                                                   how='outer', on=['CHROM', 'POS']).merge(temp_dfs['varscan'][['CHROM', 'POS', 'FILTER_PASS']], \n",
    "                                                   how='outer', on=['CHROM', 'POS'], suffixes=['_vardict', '_varscan'])\n",
    "    truth_df = pd.read_csv(dataset+'/'+dataset+'_truth.bed', delimiter='\\t', header=0, names=['CHROM', 'START_POS', 'END_POS'])\n",
    "    combined_df = merged.merge(truth_df[['CHROM', 'START_POS']], how='outer', left_on=['CHROM', 'POS'], right_on=['CHROM', 'START_POS'])\n",
    "    combined_df['y'] = combined_df['START_POS'].notna()\n",
    "\n",
    "    combined_df['FILTER_PASS_freebayes'] = combined_df['FILTER_PASS_freebayes'].fillna(-1).astype(int)\n",
    "    combined_df['FILTER_PASS_mutect2'] = combined_df['FILTER_PASS_mutect2'].fillna(-1).astype(int)\n",
    "    combined_df['FILTER_PASS_vardict'] = combined_df['FILTER_PASS_vardict'].fillna(-1).astype(int)\n",
    "    combined_df['FILTER_PASS_varscan'] = combined_df['FILTER_PASS_varscan'].fillna(-1).astype(int)\n",
    "    combined_df['y_true'] = combined_df['y'].astype(int) \n",
    "    dfs[dataset] = combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee381e-7e2d-49ad-b773-235b12831f06",
   "metadata": {},
   "source": [
    "### 2.2 Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18d3444-9f54-4f19-8b0b-db715e00508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'wb') as fp:\n",
    "    pickle.dump(dfs, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978a507-386e-404a-be49-7ba3b8dc9a8c",
   "metadata": {},
   "source": [
    "### 2.3 Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "143af7a3-e9e5-4fe0-8d30-6c7de32c049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = None\n",
    "with open('data.pkl', 'rb') as fp:\n",
    "    p_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ce87d72-6df7-49b0-91d9-dfff64c6173e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>FILTER_PASS_freebayes</th>\n",
       "      <th>FILTER_PASS_mutect2</th>\n",
       "      <th>FILTER_PASS_vardict</th>\n",
       "      <th>FILTER_PASS_varscan</th>\n",
       "      <th>START_POS</th>\n",
       "      <th>y</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10177.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10583.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12783.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13118.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CHROM      POS  FILTER_PASS_freebayes  FILTER_PASS_mutect2  \\\n",
       "0     1  10177.0                      0                   -1   \n",
       "1     1  10583.0                      0                   -1   \n",
       "2     1  12783.0                      0                   -1   \n",
       "3     1  13116.0                      0                   -1   \n",
       "4     1  13118.0                      0                   -1   \n",
       "\n",
       "   FILTER_PASS_vardict  FILTER_PASS_varscan  START_POS      y  y_true  \n",
       "0                   -1                    0        NaN  False       0  \n",
       "1                    0                    0        NaN  False       0  \n",
       "2                    0                    0        NaN  False       0  \n",
       "3                    0                   -1        NaN  False       0  \n",
       "4                    0                   -1        NaN  False       0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data['real1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0f6b03f-966c-43c7-8d87-0cef94d70bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['real1', 'syn1', 'syn2', 'syn3', 'syn4', 'syn5'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b3b79c-cad9-4e9f-8d42-18dc8599798c",
   "metadata": {},
   "source": [
    "## 3. Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb0be6c-d4ca-4079-ab42-b5de23686dbf",
   "metadata": {},
   "source": [
    "### 3.1 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9a2ed71-7e34-4265-938e-5606d1b36b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.75\n",
    "seed = 42\n",
    "features = ['FILTER_PASS_freebayes', 'FILTER_PASS_mutect2', 'FILTER_PASS_vardict', 'FILTER_PASS_varscan']\n",
    "target = ['y_true']\n",
    "df = p_data['real1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fdfd8d-d4a3-4200-8ecc-fa7919289b0d",
   "metadata": {},
   "source": [
    "### 3.2 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "10876695-e097-48aa-ad4a-2e70f2ea7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(p_data['real1'][features], p_data['real1'][target], train_size = split_ratio, stratify = p_data['real1'][target])\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    print(y_train.value_counts().to_dict())\n",
    "    print(y_test.value_counts().to_dict())\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc230a18-18b6-411e-b3af-4b75f8d80d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4342672, 4)\n",
      "(1447558, 4)\n",
      "(4342672, 1)\n",
      "(1447558, 1)\n",
      "{(0,): 4341684, (1,): 988}\n",
      "{(0,): 1447228, (1,): 330}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb3069-74bc-4bba-ae33-fb20ceb59313",
   "metadata": {},
   "source": [
    "### 3.3 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a63d2360-4e97-479c-965b-6e57ce377c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2381842/1633099542.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=seed)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59e437d5-8a78-4f1b-b650-f15b37b51be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1447228\n",
      "           1       0.83      0.80      0.81       330\n",
      "\n",
      "    accuracy                           1.00   1447558\n",
      "   macro avg       0.91      0.90      0.91   1447558\n",
      "weighted avg       1.00      1.00      1.00   1447558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f554b328-69fd-4c92-aec7-be3016ee2ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2381842/2753668790.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "/tmp/ipykernel_2381842/2753668790.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "/tmp/ipykernel_2381842/2753668790.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "/tmp/ipykernel_2381842/2753668790.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "/tmp/ipykernel_2381842/2753668790.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "/tmp/ipykernel_2381842/2753668790.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'real1': {'Precision': 0.8275862068965517, 'Recall': 0.8, 'F1 Score': 0.8135593220338982}, 'syn1': {'Precision': 0.8275862068965517, 'Recall': 0.8, 'F1 Score': 0.8135593220338982}, 'syn2': {'Precision': 0.8275862068965517, 'Recall': 0.8, 'F1 Score': 0.8135593220338982}, 'syn3': {'Precision': 0.8275862068965517, 'Recall': 0.8, 'F1 Score': 0.8135593220338982}, 'syn4': {'Precision': 0.8275862068965517, 'Recall': 0.8, 'F1 Score': 0.8135593220338982}, 'syn5': {'Precision': 0.8275862068965517, 'Recall': 0.8, 'F1 Score': 0.8135593220338982}}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for file in p_data.keys():\n",
    "    df = p_data[file]\n",
    "    clf = RandomForestClassifier(random_state=seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    results[file] = {}\n",
    "    results[file]['Precision'] = precision_score(y_test, y_pred)\n",
    "    results[file]['Recall'] = recall_score(y_test, y_pred)\n",
    "    results[file]['F1 Score'] = f1_score(y_test, y_pred)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dcc4ec17-370d-4d40-9c73-0432717f9c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'real1': {'Precision': 0.8275862068965517,\n",
       "  'Recall': 0.8,\n",
       "  'F1 Score': 0.8135593220338982},\n",
       " 'syn1': {'Precision': 0.8275862068965517,\n",
       "  'Recall': 0.8,\n",
       "  'F1 Score': 0.8135593220338982},\n",
       " 'syn2': {'Precision': 0.8275862068965517,\n",
       "  'Recall': 0.8,\n",
       "  'F1 Score': 0.8135593220338982},\n",
       " 'syn3': {'Precision': 0.8275862068965517,\n",
       "  'Recall': 0.8,\n",
       "  'F1 Score': 0.8135593220338982},\n",
       " 'syn4': {'Precision': 0.8275862068965517,\n",
       "  'Recall': 0.8,\n",
       "  'F1 Score': 0.8135593220338982},\n",
       " 'syn5': {'Precision': 0.8275862068965517,\n",
       "  'Recall': 0.8,\n",
       "  'F1 Score': 0.8135593220338982}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
